# TRUST-AID
TRUstworthy Shapley &amp; SAFE for AI in Diagnosis

### Explainable Breast Cancer Classification with SAFE AI and Shapley-Lorenz
This repository contains the code and results developed for the master’s thesis project in the Master in Artificial Intelligence for Healthcare at the University of Pavia. (XAIM)

The project explores the application of explainability techniques to support trustworthy AI in breast cancer diagnosis. Three machine learning classifiers—Logistic Regression, Random Forest, and XGBoost—were trained on the Breast Cancer Wisconsin dataset. Their predictions were analyzed using two interpretability frameworks:

SAFE AI: a model-agnostic method that evaluates global explainability and robustness (RGE and RGR).

Shapley-Lorenz: a Shapley-based method incorporating fairness-aware feature attribution via Lorenz zonoids.

The aim of this work is to compare and combine the strengths of both methods to enhance model transparency and support clinical decision-making.
